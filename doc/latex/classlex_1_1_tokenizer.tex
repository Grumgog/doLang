\hypertarget{classlex_1_1_tokenizer}{}\section{Класс lex\+:\+:Tokenizer}
\label{classlex_1_1_tokenizer}\index{lex\+::\+Tokenizer@{lex\+::\+Tokenizer}}


Виртуальный класс для токенизаторов  




{\ttfamily \#include $<$lexer.\+h$>$}

\subsection*{Открытые члены}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classlex_1_1_tokenizer_a6fd22f79c30b936923c2e408eaaf835c}\label{classlex_1_1_tokenizer_a6fd22f79c30b936923c2e408eaaf835c}} 
virtual \hyperlink{classlex_1_1_token}{Token} {\bfseries analysis} (std\+::string lex)=0
\end{DoxyCompactItemize}


\subsection{Подробное описание}
Виртуальный класс для токенизаторов 

\begin{DoxyAuthor}{Автор}
grumgog 
\end{DoxyAuthor}
\begin{DoxyDate}{Дата}
27.\+06.\+2018 
\end{DoxyDate}
\begin{DoxyVersion}{Версия}
0.\+2
\end{DoxyVersion}
Токенизатор -\/ класс для определения типа лексемы. один тип -\/ один токенизатор 

Объявления и описания членов класса находятся в файле\+:\begin{DoxyCompactItemize}
\item 
C\+:/\+Users/днс/\+Desktop/\+Work\+On/do\+Lang/src/lexer.\+h\end{DoxyCompactItemize}
