\hypertarget{classlex_1_1_lexer}{}\section{Класс lex\+:\+:Lexer}
\label{classlex_1_1_lexer}\index{lex\+::\+Lexer@{lex\+::\+Lexer}}


Класс лексического анализатора  




{\ttfamily \#include $<$lexer.\+h$>$}

\subsection*{Открытые члены}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classlex_1_1_lexer_a4c3c63439f64bf232e8995aaa555a7e4}\label{classlex_1_1_lexer_a4c3c63439f64bf232e8995aaa555a7e4}} 
{\bfseries Lexer} (\mbox{\hyperlink{classlex_1_1_divider}{Divider}} $\ast$div\+Obj, std\+::vector$<$ \mbox{\hyperlink{classlex_1_1_tokenizer}{Tokenizer}} $\ast$$>$ t=std\+::vector$<$ \mbox{\hyperlink{classlex_1_1_tokenizer}{Tokenizer}} $\ast$$>$())
\item 
\mbox{\Hypertarget{classlex_1_1_lexer_a64c1af615d7d401c0e6fcbf0c0c8e02b}\label{classlex_1_1_lexer_a64c1af615d7d401c0e6fcbf0c0c8e02b}} 
{\bfseries Lexer} (\mbox{\hyperlink{classlex_1_1_divider}{Divider}} $\ast$div\+Obj, \mbox{\hyperlink{classlex_1_1_tokenizer}{Tokenizer}} $\ast$one)
\item 
\mbox{\Hypertarget{classlex_1_1_lexer_a950c6154df77c2be981ae428d901eb48}\label{classlex_1_1_lexer_a950c6154df77c2be981ae428d901eb48}} 
void {\bfseries add\+Tokenizer} (\mbox{\hyperlink{classlex_1_1_tokenizer}{Tokenizer}} $\ast$t)
\item 
\mbox{\Hypertarget{classlex_1_1_lexer_aa07e79c06cf0c6cddb8298f5251c8233}\label{classlex_1_1_lexer_aa07e79c06cf0c6cddb8298f5251c8233}} 
void {\bfseries set\+Divider} (\mbox{\hyperlink{classlex_1_1_divider}{Divider}} $\ast$d)
\item 
\mbox{\Hypertarget{classlex_1_1_lexer_a8bb714aa6804f70ad492812953ceb63e}\label{classlex_1_1_lexer_a8bb714aa6804f70ad492812953ceb63e}} 
std\+::vector$<$ std\+::string $>$ {\bfseries divide\+Lex} (std\+::string str)
\item 
\mbox{\Hypertarget{classlex_1_1_lexer_aaecb73d7dce83e7dc0bbea31a8d2ead5}\label{classlex_1_1_lexer_aaecb73d7dce83e7dc0bbea31a8d2ead5}} 
std\+::vector$<$ \mbox{\hyperlink{classlex_1_1_token}{Token}} $>$ {\bfseries tokenize} (std\+::vector$<$ std\+::string $>$ lexs)
\item 
\mbox{\Hypertarget{classlex_1_1_lexer_aed0a4a34bf17a219fec3c9d51d9970aa}\label{classlex_1_1_lexer_aed0a4a34bf17a219fec3c9d51d9970aa}} 
std\+::vector$<$ \mbox{\hyperlink{classlex_1_1_token}{Token}} $>$ {\bfseries process} (std\+::string input)
\end{DoxyCompactItemize}


\subsection{Подробное описание}
Класс лексического анализатора 

\begin{DoxyAuthor}{Автор}
grumgog 
\end{DoxyAuthor}
\begin{DoxyDate}{Дата}
27.\+06.\+2018 
\end{DoxyDate}
\begin{DoxyVersion}{Версия}
0.\+2
\end{DoxyVersion}
Лексический анализатор -\/ модуль занимающийся разбором строки на лексемы -\/ самостоятельные \char`\"{}слова\char`\"{} языка. Для определения токенов, нужно добавить типы токенов -\/ объекты классов унаследованных от Token\+Type. Для правильного определения типа токена, рекомендуеться добавлять типы токенов от более конкретного к более общему случаю. Например целые\+\_\+числа $<$-\/ вещественные\+\_\+числа. Класс сам очищяет память под выделенные данные, в своем деструкторе, поэтому дополнительных действий по очистке памяти не нужно. 

Объявления и описания членов классов находятся в файлах\+:\begin{DoxyCompactItemize}
\item 
C\+:/\+Users/grumgog/\+Desktop/\+Work\+On/do\+Lang/src/lexer.\+h\item 
C\+:/\+Users/grumgog/\+Desktop/\+Work\+On/do\+Lang/src/lexer.\+cpp\end{DoxyCompactItemize}
